{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5a06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fefc6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_csv_to_list_rating(file_path):\n",
    "    \"\"\"Read a CSV file into a list of lists with specific column types.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)  # Read the header\n",
    "        matrix = []\n",
    "        for values in reader:\n",
    "            row = [int(values[0]), int(values[1]), float(values[2]), int(values[3])]\n",
    "            matrix.append(row)\n",
    "        return header, matrix\n",
    "\n",
    "def read_csv_to_list_movies(file_path):\n",
    "    \"\"\"Read a CSV file into a list of lists with specific column types.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)  # Read the header\n",
    "        matrix = []\n",
    "        index = 1\n",
    "        matrix.append([0, \"\", \"\"])  # Initial dummy row\n",
    "        for values in reader:\n",
    "            while index < int(values[0]):\n",
    "                matrix.append([0, \"\", \"\"])\n",
    "                index += 1\n",
    "            row = [int(values[0]), str(values[1]), str(values[-1])]\n",
    "            matrix.append(row)\n",
    "            index += 1\n",
    "        return header, matrix\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff870a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200949\n",
      "292758\n"
     ]
    }
   ],
   "source": [
    "headerMovies, matrixMovies = read_csv_to_list_movies('movies.csv')\n",
    "headerRating, matrixrating = read_csv_to_list_rating('ratings.csv')\n",
    "\n",
    "\n",
    "totalRaters = int(matrixrating[-1][0])+1  # total rows\n",
    "totalMovies = int(matrixMovies[-1][0])+1\n",
    "print(totalRaters)\n",
    "print(totalMovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dbf63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d42f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\n",
    "    'ratings.csv',\n",
    "    sep=',',\n",
    "    names=['userId', 'movieId', 'rating', 'timestamp'],\n",
    "    dtype={'userId': int, 'movieId': int, 'rating': float, 'timestamp': int},\n",
    "    skiprows=1  \n",
    ")\n",
    "ratings = ratings.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e002b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\n",
    "    'movies.csv',\n",
    "    sep=',',\n",
    "    names=['movieId', 'title', 'genres'],\n",
    "    dtype={'movieId': int, 'title': str, 'genres': str},\n",
    "    skiprows=1  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "857c6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "ratings['user'] = user_encoder.fit_transform(ratings['userId'])\n",
    "ratings['movie'] = item_encoder.fit_transform(ratings['movieId'])\n",
    "\n",
    "num_users = ratings['user'].nunique()\n",
    "num_items = ratings['movie'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bcc0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, ratings):\n",
    "        self.users = torch.tensor(ratings['user'].values, dtype=torch.long)\n",
    "        self.items = torch.tensor(ratings['movie'].values, dtype=torch.long)\n",
    "        self.labels = torch.tensor(ratings['rating'].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e4285b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = MovieLensDataset(ratings)\n",
    "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66814513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NeuralCollaborativeFiltering(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # Predicts single score\n",
    "        )\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        x = torch.cat([user_emb, item_emb], dim=-1)\n",
    "        x = self.mlp(x)\n",
    "        return x  # <-- NO SIGMOID\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d45fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralCollaborativeFiltering(num_users, num_items).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b911166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d495111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.amp.GradScaler(device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a150782a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.5591139486923488\n",
      "Epoch 2: Loss = 0.5260077427711141\n",
      "Epoch 3: Loss = 0.5172322894108932\n",
      "Epoch 4: Loss = 0.5102464158099532\n",
      "Epoch 5: Loss = 0.5038575175821196\n",
      "Epoch 6: Loss = 0.4953703712316167\n",
      "Epoch 7: Loss = 0.48415115563675926\n",
      "Epoch 8: Loss = 0.4736156114455906\n",
      "Epoch 9: Loss = 0.4640872312198238\n",
      "Epoch 10: Loss = 0.45654580643919274\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for user_ids, item_ids, labels in dataloader:\n",
    "        user_ids, item_ids, labels = user_ids.cuda(), item_ids.cuda(), labels.cuda()\n",
    "        labels = (labels >= 4).float()  # Treat ratings >= 4 as \"positive\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.autocast(device_type='cuda'):\n",
    "            outputs = model(user_ids, item_ids).squeeze()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2a3dcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended movie IDs: [29428 17982 26754 34343 44956]\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Switch to evaluation mode\n",
    "\n",
    "user_id = torch.tensor([1]).cuda()  # Some user\n",
    "candidate_movie_ids = torch.arange(num_items).cuda()  # All movies\n",
    "\n",
    "# Expand user_id to match movie_ids\n",
    "user_ids = user_id.expand_as(candidate_movie_ids)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(user_ids, candidate_movie_ids).squeeze()\n",
    "    scores = torch.sigmoid(predictions)  # Now apply sigmoid manually in evaluation\n",
    "\n",
    "# Recommend top 5 movies\n",
    "topk = torch.topk(scores, 5)\n",
    "print(\"Top 5 recommended movie IDs:\", topk.indices.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b4fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "879cd7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieId 135492: Kaaka Muttai (2015)\n",
      "MovieId 93988: North & South (2004)\n",
      "MovieId 128684: Artifact (2012)\n",
      "MovieId 147250: The Adventures of Sherlock Holmes and Doctor Watson\n",
      "MovieId 172587: Vacations in Prostokvashino (1980)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load movie metadata\n",
    "movies = pd.read_csv('movies.csv')\n",
    "\n",
    "# Your LabelEncoder for items (movieId)\n",
    "# item_encoder = LabelEncoder()\n",
    "# item_encoder.fit(ratings['movieId'])  # you did this earlier\n",
    "\n",
    "# Your top recommended internal IDs\n",
    "top_movie_indices = topk.indices.cpu().numpy()  # [591, 536, 600, 734, 658]\n",
    "\n",
    "# Decode back to original MovieLens movieIds\n",
    "top_movie_ids = item_encoder.inverse_transform(top_movie_indices)\n",
    "\n",
    "# Now match with movie titles\n",
    "recommended_movies = movies[movies['movieId'].isin(top_movie_ids)]\n",
    "\n",
    "# Print nicely\n",
    "for movieId in top_movie_ids:\n",
    "    title = movies[movies['movieId'] == movieId]['title'].values[0]\n",
    "    print(f\"MovieId {movieId}: {title}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
